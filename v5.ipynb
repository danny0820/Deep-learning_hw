{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNUara7gg-Wo"
      },
      "source": [
        "# 2025 DL Lab3: Semi-Supervised Flower Classfication"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVFSdNlBg-Wr"
      },
      "source": [
        "Before we start, please put **your name** and **SID** in following format: <br>\n",
        "Hi I'm 陸仁賈, 314831000."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXhizSoQg-Ws"
      },
      "source": [
        "**Your Answer:**    \n",
        "Hi I'm 戴良育, 314834012."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEyUf73Ag-Wt"
      },
      "source": [
        "## Semi-supervised Flower Classfication\n",
        "\n",
        "In this approach, you have a dataset that includes both labeled and unlabeled examples.\n",
        "\n",
        "The goal is to use the labeled data to train the model while also leveraging the unlabeled\n",
        "data to improve the model's performance.\n",
        "\n",
        "In this assignment, you’ll explore a self-training mechanism for this task.\n",
        "\n",
        "\n",
        "**Please note that you’re not allowed to use pre-constructed models or pre-trained weights.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TQMhhODg-Wu"
      },
      "source": [
        "## Kaggle Competition\n",
        "Kaggle is an online community of data scientists and machine learning practitioners. Kaggle allows users to find and publish datasets, explore and build models in a web-based data-science environment, work with other data scientists and machine learning engineers, and enter competitions to solve data science challenges.\n",
        "\n",
        "This assignment use kaggle to calculate your grade.  \n",
        "Please use this [**LINK**](https://www.kaggle.com/t/a611e0096e5943cc99a1c0545be28c3c) to join the competition.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HIWWsPsg-Wv"
      },
      "source": [
        "##  Versions of used packages\n",
        "\n",
        "We will check PyTorch version to make sure everything work properly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TzquNaqg-Ww",
        "outputId": "783479fd-544a-4ce3-e407-90b675bd8581"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python 3.13.5 | packaged by Anaconda, Inc. | (main, Jun 12 2025, 16:37:03) [MSC v.1929 64 bit (AMD64)]\n",
            "torch 2.8.0+cu126\n",
            "torchvision 0.23.0+cu126\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import torch\n",
        "import torchvision\n",
        "print('python', sys.version.split('\\n')[0])\n",
        "print('torch', torch.__version__)\n",
        "print('torchvision', torchvision.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzu9D8_jg-Xd"
      },
      "source": [
        "# Prepare Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmLG1fxtg-Xf"
      },
      "source": [
        "We use [Flowers Recognition](https://www.kaggle.com/alxmamaev/flowers-recognition) dataset.\n",
        "This is collected by Alexander Mamaev.\n",
        "\n",
        "**Abstrct**  \n",
        "\n",
        "We clean the dataset,this dataset contains 4262 flower images.   \n",
        "**IMPORTANT: you CANNOT use any extra images.**\n",
        "\n",
        "The data collection is grabed from the data flicr, google images, yandex images.\n",
        "You can use this datastet to recognize plants from the photo.\n",
        "\n",
        "The pictures are divided into five classes:\n",
        "+ daisy\n",
        "+ tulip\n",
        "+ rose\n",
        "+ sunflower\n",
        "+ dandelion\n",
        "\n",
        "For each class there are about 800 photos. Photos are not high resolution, about 320x240 pixels. Photos are not reduced to a single size, they have different proportions!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06j-NW_xg-Xg"
      },
      "source": [
        "## Unzip Data\n",
        "\n",
        "Unzip `Lab3_data_flower_2025.zip`, there are 3 folders.\n",
        "\n",
        "- `train/`: 6 subfolders total.\n",
        "   - `daisy/`, `dandelion/`, `rose/`, `sunflower/`, `tulip/`: labeled training images.\n",
        "   - `unlabel/`: unlabeled training images.\n",
        "contains 6 folders for 5 categories of flowers. Images of flowers inside them.\n",
        "- `val/`: contains 5 folders for the same 5 classes. Labeled validation images for each class.\n",
        "- `test/`: unclassified images of testing set.\n",
        "---\n",
        "\n",
        "There are **1200 images in labeled training set.**  \n",
        "\n",
        "There are **1202 images in unlabeled training set.**\n",
        "\n",
        "There are **678 images in validation set.**\n",
        "\n",
        "There are **1215 images in test set.**  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqapE3HLg-Xg"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cl4ngyLNg-Xg"
      },
      "outputs": [],
      "source": [
        "data_folder = 'Lab3_data_flower_2025'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwRBft5Ig-Xh"
      },
      "source": [
        "### Custom dataset\n",
        "\n",
        "Build a classs inherit `torch.utils.data.Dataset`.  \n",
        "Implement `__init__`, `__getitem__` and `__len__` 3 functions.  \n",
        "\n",
        "Some operations could be there: setting location of dataset, the method of reading data, label of dataset or transform of dataset.\n",
        "\n",
        "See [torch.utils.data.Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) for more details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UahKTzvTg-Xh"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import os.path as osp\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "import pandas as pd\n",
        "\n",
        "CLASS_NAMES = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n",
        "CLASS_TO_IDX = {c:i for i, c in enumerate(CLASS_NAMES)}\n",
        "VALID_EXTS = {'.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff', '.webp'}\n",
        "\n",
        "class FlowerData(Dataset):\n",
        "    def __init__(self, root, split='train', mode='train', transform=None, use_unlabel=False):\n",
        "        self.root = Path(root)\n",
        "        self.split = split\n",
        "        self.mode = mode\n",
        "        self.transform = transform\n",
        "        self.use_unlabel = use_unlabel\n",
        "\n",
        "        self.paths = []\n",
        "        self.labels = []\n",
        "        self.rel_paths = []\n",
        "\n",
        "        # Load data from unified CSV files\n",
        "        if split == 'train' and use_unlabel:\n",
        "            csv_file = self.root / 'unlabeled_train.csv'\n",
        "        elif split == 'train':\n",
        "            csv_file = self.root / 'train.csv'\n",
        "        elif split == 'val':\n",
        "            csv_file = self.root / 'val.csv'\n",
        "        else:  # test\n",
        "            csv_file = self.root / 'test.csv'\n",
        "\n",
        "        # Read CSV file using pandas for better handling\n",
        "        df = pd.read_csv(csv_file)\n",
        "\n",
        "        for _, row in df.iterrows():\n",
        "            file_path = self.root / row['file_name']\n",
        "            self.paths.append(file_path)\n",
        "            self.rel_paths.append(row['file_name'])\n",
        "\n",
        "            # Handle labels\n",
        "            if split == 'test' or (split == 'train' and use_unlabel):\n",
        "                # No labels for test or unlabeled data\n",
        "                pass\n",
        "            else:\n",
        "                # For labeled data\n",
        "                if pd.isna(row['groundtruth']) or row['groundtruth'] == '':\n",
        "                    self.labels.append(-1)  # Invalid label for debugging\n",
        "                else:\n",
        "                    self.labels.append(CLASS_TO_IDX[row['groundtruth']])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.paths[index]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.mode == 'test' or (self.split == 'train' and self.use_unlabel):\n",
        "            return img\n",
        "        label = int(self.labels[index])\n",
        "        return img, torch.tensor(label, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B20CKxeig-Xj"
      },
      "source": [
        "### Data augmentation\n",
        "\n",
        "Data augmentation are techniques used to increase the amount of data by adding slightly modified copies of already existing data or newly created synthetic data from existing data.\n",
        "\n",
        "PyTorch use `torchvision.transforms` to do data augmentation.\n",
        "[You can see all function here.](https://docs.pytorch.org/vision/main/transforms.html)  \n",
        "\n",
        "There are some operations may not be necessary for predict, so we should write one for train and one for others.  \n",
        "**NOTICE**：Please use v2 instead of transform cause some of function in v1 will be removed in the following version pytorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TtaoreYhg-Xk"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import v2 as transforms\n",
        "# For TRAIN\n",
        "########################################################################\n",
        "#  TODO: use transforms.xxx method to do some data augmentation        #\n",
        "#  This one is for training, find the composition to get better result #\n",
        "########################################################################\n",
        "transforms_train = transforms.Compose([\n",
        "    # 隨機裁切與縮放，避免直接拉伸圖片\n",
        "    transforms.RandomResizedCrop(\n",
        "        size=224,\n",
        "        scale=(0.6, 1.0),           # 放寬取樣比例，讓視角更豐富\n",
        "        ratio=(0.75, 1.33),\n",
        "        antialias=True\n",
        "    ),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "\n",
        "    # 自動增強：使用 TrivialAugmentWide 或 RandAugment（二者擇一）\n",
        "    transforms.TrivialAugmentWide(),\n",
        "    # 若版本不支援 TrivialAugmentWide，可用 RandAugment 代替：\n",
        "    # transforms.RandAugment(num_ops=2, magnitude=7),\n",
        "\n",
        "    # 色彩抖動：使用 RandomApply 包裹，避免每張都強度過高\n",
        "    transforms.RandomApply([\n",
        "        transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1)\n",
        "    ], p=0.5),\n",
        "\n",
        "    # 少量轉灰階，提高對顏色變化的穩健度\n",
        "    transforms.RandomGrayscale(p=0.05),\n",
        "\n",
        "    # 轉成 Tensor 並做正規化\n",
        "    transforms.ToImage(),\n",
        "    transforms.ToDtype(torch.float32, scale=True),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "\n",
        "    # 遮擋式正則：RandomErasing\n",
        "    transforms.RandomErasing(p=0.25, scale=(0.02, 0.12), ratio=(0.3, 3.3))\n",
        "])\n",
        "########################################################################\n",
        "#                           End of your code                           #\n",
        "########################################################################\n",
        "\n",
        "# For VAL, TEST\n",
        "########################################################################\n",
        "#  TODO: use transforms.xxx method to do some data augmentation        #\n",
        "#  This one is for validate and test,                                  #\n",
        "#  NOTICE some operation we usually not use in this part               #\n",
        "########################################################################\n",
        "transforms_test = transforms.Compose([\n",
        "    transforms.Resize(256, antialias=True),  # 維持長寬比\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToImage(),\n",
        "    transforms.ToDtype(torch.float32, scale=True),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "########################################################################\n",
        "#                           End of your code                           #\n",
        "########################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3vwqtuGg-Xk"
      },
      "source": [
        "### Instantiate dataset\n",
        "\n",
        "Let's instantiate three `FlowerData` class.\n",
        "+ train_set: for labeled_training.\n",
        "+ unlabeled_set: for unlabeled_training.\n",
        "+ dataset_val: for validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEBdnX6vg-Xk",
        "outputId": "8bdf0dbc-3c07-473e-88e4-0e6482fdf631"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The first image's shape in dataset_train : torch.Size([3, 224, 224])\n",
            "There are 1200 images in labeled_dataset_train.\n",
            "There are 1202 images in unlabeled_dataset_train.\n",
            "There are 678 images in dataset_val.\n",
            "\n",
            "Verifying data loading with new CSV format:\n",
            "Train set - first sample label: 0\n",
            "Train set - file path: train/daisy/14167534527_781ceb1b7a_n.jpg\n",
            "Unlabeled set - file path: train/unlabel/unlabel_51e2a07b21.jpg\n",
            "Val set - first sample label: 0\n",
            "Val set - file path: val/daisy/521762040_f26f2e08dd.jpg\n"
          ]
        }
      ],
      "source": [
        "train_set       = FlowerData(data_folder, split='train', mode='train', transform=transforms_train, use_unlabel=False)\n",
        "unlabeled_set   = FlowerData(data_folder, split='train', mode='test',  transform=transforms_test,  use_unlabel=True)  # train/unlabel\n",
        "valid_set       = FlowerData(data_folder, split='val',   mode='train', transform=transforms_test,  use_unlabel=False)\n",
        "\n",
        "num_classes = len(CLASS_NAMES)\n",
        "print(\"The first image's shape in dataset_train :\", train_set[0][0].size())\n",
        "print(\"There are\", len(train_set), \"images in labeled_dataset_train.\")\n",
        "print(\"There are\", len(unlabeled_set), \"images in unlabeled_dataset_train.\")\n",
        "print(\"There are\", len(valid_set), \"images in dataset_val.\")\n",
        "\n",
        "# Verify the new format by checking a few samples\n",
        "print(\"\\nVerifying data loading with new CSV format:\")\n",
        "print(\"Train set - first sample label:\", train_set[0][1].item() if len(train_set) > 0 else \"No data\")\n",
        "print(\"Train set - file path:\", train_set.rel_paths[0] if len(train_set) > 0 else \"No data\")\n",
        "print(\"Unlabeled set - file path:\", unlabeled_set.rel_paths[0] if len(unlabeled_set) > 0 else \"No data\")\n",
        "print(\"Val set - first sample label:\", valid_set[0][1].item() if len(valid_set) > 0 else \"No data\")\n",
        "print(\"Val set - file path:\", valid_set.rel_paths[0] if len(valid_set) > 0 else \"No data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jxg6uZ2Fg-Xk"
      },
      "source": [
        "### DataLoader\n",
        "\n",
        "`torch.utils.data.DataLoader` define how to sample from `dataset` and some other function like:\n",
        "+ shuffle : set to `True` to have the data reshuffled at every epoch\n",
        "+ batch_size : how many samples per batch to load\n",
        "\n",
        "See [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) for more details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "N1SYf10fg-Xk"
      },
      "outputs": [],
      "source": [
        "#####################################################\n",
        "#            You can adjust batch_size              #\n",
        "#####################################################\n",
        "batch_size = 32\n",
        "num_workers = 0\n",
        "loader_kwargs = dict(batch_size=batch_size, num_workers=num_workers, pin_memory=torch.cuda.is_available())\n",
        "# if num_workers > 0:\n",
        "#     loader_kwargs[\"persistent_workers\"] = True\n",
        "\n",
        "train_loader = DataLoader(train_set, shuffle=True,drop_last=True, **loader_kwargs)\n",
        "val_loader   = DataLoader(valid_set, shuffle=False, **loader_kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXWHwfKWg-Xl"
      },
      "source": [
        "Finally! We have made all data prepared.  \n",
        "Let's go develop our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbci5FYUg-Xl"
      },
      "source": [
        "# Self-training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IG5dXyEg-Xl"
      },
      "source": [
        "## Step 1: Supervised training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evToJigsg-Xl"
      },
      "source": [
        "### Implement CNN using PyTorch\n",
        "\n",
        "Try to use labeled data design and train a deep convolutional network from scratch to predict the class label of a flower image.\n",
        "\n",
        "**Again, the goal of this assignment is for you to test different convolutional structures. You cannot directly use the blocks/architectures of pre-trained models.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Jnfnpc4dMH8d"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    ResNet BasicBlock\n",
        "    \"\"\"\n",
        "    expansion = 1\n",
        "    def __init__(self, in_c, out_c, stride=1, downsample=None):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_c, out_c, 3, stride, 1, bias=False)\n",
        "        self.bn1   = nn.BatchNorm2d(out_c)\n",
        "        self.relu  = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_c, out_c, 3, 1, 1, bias=False)\n",
        "        self.bn2   = nn.BatchNorm2d(out_c)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = self.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "        out = self.relu(out + identity)\n",
        "        return out\n",
        "\n",
        "\n",
        "def make_layer(in_c, out_c, blocks, stride):\n",
        "    \"\"\"\n",
        "    創建 ResNet layer\n",
        "    \"\"\"\n",
        "    down = None\n",
        "    if stride != 1 or in_c != out_c:\n",
        "        down = nn.Sequential(\n",
        "            nn.Conv2d(in_c, out_c, 1, stride, bias=False),\n",
        "            nn.BatchNorm2d(out_c)\n",
        "        )\n",
        "    layers = [BasicBlock(in_c, out_c, stride, down)]\n",
        "    for _ in range(1, blocks):\n",
        "        layers.append(BasicBlock(out_c, out_c))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class ResNet34(nn.Module):\n",
        "    \"\"\"\n",
        "    ResNet34 架構\n",
        "    Layer 結構：[3, 4, 6, 3] blocks\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes=5):\n",
        "        super().__init__()\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
        "        )\n",
        "        # ResNet34: [3, 4, 6, 3] blocks (vs ResNet18: [2, 2, 2, 2])\n",
        "        self.layer1 = make_layer(64,   64,  blocks=3, stride=1)\n",
        "        self.layer2 = make_layer(64,   128, blocks=4, stride=2)\n",
        "        self.layer3 = make_layer(128,  256, blocks=6, stride=2)\n",
        "        self.layer4 = make_layer(256,  512, blocks=3, stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "        # Kaiming 初始化\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.BatchNorm1d)):\n",
        "                nn.init.constant_(m.weight, 1); nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01); nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.layer1(x); x = self.layer2(x); x = self.layer3(x); x = self.layer4(x)\n",
        "        x = self.avgpool(x)\n",
        "        return self.head(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "kDP3qUpJg-Xl"
      },
      "outputs": [],
      "source": [
        "from torch.nn.modules.conv import Conv2d\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class YourCNNModel(nn.Module):\n",
        "    def __init__(self, num_classes=5):\n",
        "        super().__init__()\n",
        "        ########################################################################\n",
        "        #     TODO: use nn.xxx method to generate a CNN model part             #\n",
        "        ########################################################################\n",
        "        self.model = ResNet34(num_classes=num_classes)\n",
        "        ########################################################################\n",
        "        #                           End of your code                           #\n",
        "        ########################################################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        assert isinstance(x, torch.Tensor), \"Input should be a torch Tensor\"\n",
        "        assert x.dim() == 4, \"Input should be NHWC format\"\n",
        "        ########################################################################\n",
        "        #     TODO: forward your model and get output                          #\n",
        "        ########################################################################\n",
        "        out = self.model(x)\n",
        "        ########################################################################\n",
        "        #                           End of your code                           #\n",
        "        ########################################################################\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "X3XF1I4Kg-Xl"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda')\n",
        "# or\n",
        "# device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fQnLfLE-g-Xm"
      },
      "outputs": [],
      "source": [
        "model = YourCNNModel(num_classes=num_classes)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4E5AWe7g-Xm"
      },
      "source": [
        "We have made our model!  \n",
        "Next, PyTorch also provide many utility function(loss, optmizer...etc).  \n",
        "You can define them in one-line."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKahIOXpg-Xm"
      },
      "source": [
        "### Define loss and optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElzcjoYE-bl1"
      },
      "source": [
        "[Optimizers in pytorch](https://docs.pytorch.org/docs/stable/optim.html)  \n",
        "[CrossEntropyLoss in pytorch](https://docs.pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "abaxdaMig-Xm"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "################################################################################\n",
        "# TODO: Define loss and optmizer functions                                     #\n",
        "# Try any loss or optimizer function and learning rate to get better result    #\n",
        "# hint: torch.nn and torch.optim                                               #\n",
        "################################################################################\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.003, weight_decay=1e-4)\n",
        "################################################################################\n",
        "#                               End of your code                               #\n",
        "################################################################################\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQMKutOKg-Xn"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaC0C1H3g-Xn"
      },
      "source": [
        "#### Train function\n",
        "Let's define train function.  \n",
        "It will iterate input data 1 epoch and update model with optmizer.  \n",
        "Finally, calculate mean loss and total accuracy.\n",
        "\n",
        "Hint: [torch.max()](https://pytorch.org/docs/stable/generated/torch.max.html#torch-max) or [torch.argmax()](https://pytorch.org/docs/stable/generated/torch.argmax.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RyNN_Sd6g-Xo"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "def train(input_data, model, criterion, optimizer, epoch=None, total_epochs=None):\n",
        "    '''\n",
        "    Argement:\n",
        "    input_data -- iterable data, typr torch.utils.data.Dataloader is prefer\n",
        "    model -- nn.Module, model contain forward to predict output\n",
        "    criterion -- loss function, used to evaluate goodness of model\n",
        "    optimizer -- optmizer function, method for weight updating\n",
        "    '''\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    total_count = 0\n",
        "    acc_count = 0\n",
        "\n",
        "    desc = f\"Train | epoch {epoch}/{total_epochs}\" if epoch is not None else \"Train\"\n",
        "    pbar = tqdm(input_data, desc=desc, leave=False)\n",
        "\n",
        "    for images, labels in pbar:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        ########################################################################\n",
        "        # TODO: Forward, backward and optimize                                 #\n",
        "        # 1. zero the parameter gradients                                      #\n",
        "        # 2. process input through the network                                 #\n",
        "        # 3. compute the loss                                                  #\n",
        "        # 4. propagate gradients back into the network's parameters            #\n",
        "        # 5. Update the weights of the network                                 #\n",
        "        ########################################################################\n",
        "        optimizer.zero_grad()  # 1. 清空梯度\n",
        "        outputs = model(images)  # 2. 前向傳播，通過網路處理輸入\n",
        "        loss = criterion(outputs, labels)  # 3. 計算損失\n",
        "        loss.backward()  # 4. 反向傳播，計算梯度\n",
        "        optimizer.step()  # 5. 更新網路權重\n",
        "        ########################################################################\n",
        "        #                           End of your code                           #\n",
        "        ########################################################################\n",
        "\n",
        "\n",
        "        ########################################################################\n",
        "        # TODO: Get the counts of correctly classified images                  #\n",
        "        # 1. get the model predicted result                                    #\n",
        "        # 2. sum the number of this batch predicted images                     #\n",
        "        # 3. sum the number of correctly classified                            #\n",
        "        # 4. save this batch's loss into loss_list                             #\n",
        "        # dimension of outputs: [batch_size, number of classes]                #\n",
        "        # Hint 1: use outputs.data to get no auto_grad                         #\n",
        "        # Hint 2: use torch.max()                                              #\n",
        "        ########################################################################\n",
        "        _, predicted = torch.max(outputs.data, 1)  # 1. 獲取預測結果（最大值的索引）\n",
        "        total_count += labels.size(0)  # 2. 累加此批次的圖片數量\n",
        "        acc_count += (predicted == labels).sum().item()  # 3. 累加正確分類的數量\n",
        "        loss_list.append(loss.item())  # 4. 將此批次的損失加入列表\n",
        "        ########################################################################\n",
        "        #                           End of your code                           #\n",
        "        ########################################################################\n",
        "\n",
        "        running_acc = acc_count / total_count if total_count else 0.0\n",
        "        lr = optimizer.param_groups[0]['lr']\n",
        "        pbar.set_postfix(loss=f\"{loss.item():.4f}\", acc=f\"{running_acc:.4f}\", lr=f\"{lr:.6f}\")\n",
        "\n",
        "    acc  = acc_count / total_count if total_count else 0.0\n",
        "    loss = sum(loss_list) / len(loss_list) if loss_list else 0.0\n",
        "    return acc, loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLlLua9og-Xo"
      },
      "source": [
        "#### Validate function\n",
        "Next part is validate function.  \n",
        "It works as training function without optmizer and weight-updating part."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "EkLMA_0qg-Xo"
      },
      "outputs": [],
      "source": [
        "def val(input_data, model, criterion, epoch=None, total_epochs=None):\n",
        "    model.eval()\n",
        "    loss_list = []\n",
        "    total_count = 0\n",
        "    acc_count = 0\n",
        "\n",
        "    desc = f\"Val   | epoch {epoch}/{total_epochs}\" if epoch is not None else \"Val\"\n",
        "    pbar = tqdm(input_data, desc=desc, leave=False)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in pbar:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            ####################################################################\n",
        "            # TODO: Get the predicted result and loss                          #\n",
        "            # 1. process input through the network                             #\n",
        "            # 2. compute the loss                                              #\n",
        "            # 3. get the model predicted result                                #\n",
        "            # 4. get the counts of correctly classified images                 #\n",
        "            # 5. save this batch's loss into loss_list                         #\n",
        "            ####################################################################\n",
        "            outputs = model(images)  # 1. 前向傳播\n",
        "            loss = criterion(outputs, labels)  # 2. 計算損失\n",
        "            _, predicted = torch.max(outputs.data, 1)  # 3. 獲取預測結果\n",
        "\n",
        "            total_count += labels.size(0)  # 4. 累加圖片數量\n",
        "            acc_count += (predicted == labels).sum().item()  # 4. 累加正確分類數量\n",
        "            loss_list.append(loss.item())  # 5. 儲存損失\n",
        "            ####################################################################\n",
        "            #                         End of your code                         #\n",
        "            ####################################################################\n",
        "\n",
        "            running_acc = acc_count / total_count if total_count else 0.0\n",
        "            pbar.set_postfix(loss=f\"{loss.item():.4f}\", acc=f\"{running_acc:.4f}\")\n",
        "\n",
        "    acc  = acc_count / total_count if total_count else 0.0\n",
        "    loss = sum(loss_list) / len(loss_list) if loss_list else 0.0\n",
        "    return acc, loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOgqxiYVg-Xo"
      },
      "source": [
        "#### Training in a loop\n",
        "Call train and test function in a loop.  \n",
        "Take a break and wait."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_km16H9-g-Xp",
        "outputId": "40ae7346-4c66-41b9-81a6-9fd3366c322b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Best updated] Saved checkpoint: supurvised.pt (val_loss=1.873921)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Best updated] Saved checkpoint: supurvised.pt (val_loss=1.347375)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 3/200 ====================\n",
            "Train Acc: 0.436655 | Train Loss: 1.404377\n",
            "  Val Acc: 0.401180 |   Val Loss: 1.381492 | LR: 0.002999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Best updated] Saved checkpoint: supurvised.pt (val_loss=1.298551)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 6/200 ====================\n",
            "Train Acc: 0.445946 | Train Loss: 1.365692\n",
            "  Val Acc: 0.417404 |   Val Loss: 1.352812 | LR: 0.002994\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Best updated] Saved checkpoint: supurvised.pt (val_loss=1.288533)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Best updated] Saved checkpoint: supurvised.pt (val_loss=1.243123)\n",
            "==================== Epoch 9/200 ====================\n",
            "Train Acc: 0.458615 | Train Loss: 1.362427\n",
            "  Val Acc: 0.433628 |   Val Loss: 1.243123 | LR: 0.002988\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Best updated] Saved checkpoint: supurvised.pt (val_loss=1.173407)\n",
            "==================== Epoch 12/200 ====================\n",
            "Train Acc: 0.471284 | Train Loss: 1.312399\n",
            "  Val Acc: 0.471976 |   Val Loss: 1.173407 | LR: 0.002978\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 15/200 ====================\n",
            "Train Acc: 0.491554 | Train Loss: 1.279837\n",
            "  Val Acc: 0.474926 |   Val Loss: 1.195755 | LR: 0.002965\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Best updated] Saved checkpoint: supurvised.pt (val_loss=1.138990)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 18/200 ====================\n",
            "Train Acc: 0.492399 | Train Loss: 1.261546\n",
            "  Val Acc: 0.433628 |   Val Loss: 1.329147 | LR: 0.002950\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Best updated] Saved checkpoint: supurvised.pt (val_loss=1.095309)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 21/200 ====================\n",
            "Train Acc: 0.514358 | Train Loss: 1.224390\n",
            "  Val Acc: 0.539823 |   Val Loss: 1.123268 | LR: 0.002933\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Best updated] Saved checkpoint: supurvised.pt (val_loss=1.076084)\n",
            "==================== Epoch 24/200 ====================\n",
            "Train Acc: 0.516892 | Train Loss: 1.199091\n",
            "  Val Acc: 0.547198 |   Val Loss: 1.076084 | LR: 0.002912\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Best updated] Saved checkpoint: supurvised.pt (val_loss=1.069875)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Best updated] Saved checkpoint: supurvised.pt (val_loss=1.031050)\n",
            "==================== Epoch 27/200 ====================\n",
            "Train Acc: 0.540541 | Train Loss: 1.161448\n",
            "  Val Acc: 0.606195 |   Val Loss: 1.031050 | LR: 0.002889\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 30/200 ====================\n",
            "Train Acc: 0.538007 | Train Loss: 1.165179\n",
            "  Val Acc: 0.557522 |   Val Loss: 1.057445 | LR: 0.002864\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Best updated] Saved checkpoint: supurvised.pt (val_loss=0.980650)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 33/200 ====================\n",
            "Train Acc: 0.562500 | Train Loss: 1.132766\n",
            "  Val Acc: 0.514749 |   Val Loss: 1.641432 | LR: 0.002836\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 36/200 ====================\n",
            "Train Acc: 0.564189 | Train Loss: 1.090003\n",
            "  Val Acc: 0.584071 |   Val Loss: 1.030149 | LR: 0.002805\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Best updated] Saved checkpoint: supurvised.pt (val_loss=0.955428)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 39/200 ====================\n",
            "Train Acc: 0.594595 | Train Loss: 1.059387\n",
            "  Val Acc: 0.631268 |   Val Loss: 0.958417 | LR: 0.002773\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 42/200 ====================\n",
            "Train Acc: 0.599662 | Train Loss: 1.030631\n",
            "  Val Acc: 0.587021 |   Val Loss: 0.994435 | LR: 0.002738\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Best updated] Saved checkpoint: supurvised.pt (val_loss=0.947885)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Best updated] Saved checkpoint: supurvised.pt (val_loss=0.893977)\n",
            "==================== Epoch 45/200 ====================\n",
            "Train Acc: 0.591216 | Train Loss: 1.048078\n",
            "  Val Acc: 0.646018 |   Val Loss: 0.893977 | LR: 0.002701\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Best updated] Saved checkpoint: supurvised.pt (val_loss=0.885784)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 48/200 ====================\n",
            "Train Acc: 0.592905 | Train Loss: 1.052662\n",
            "  Val Acc: 0.628319 |   Val Loss: 0.917559 | LR: 0.002661\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Best updated] Saved checkpoint: supurvised.pt (val_loss=0.862075)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 51/200 ====================\n",
            "Train Acc: 0.592905 | Train Loss: 1.009825\n",
            "  Val Acc: 0.623894 |   Val Loss: 0.946633 | LR: 0.002620\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 54/200 ====================\n",
            "Train Acc: 0.642736 | Train Loss: 0.948609\n",
            "  Val Acc: 0.678466 |   Val Loss: 0.863124 | LR: 0.002577\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Best updated] Saved checkpoint: supurvised.pt (val_loss=0.811635)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 57/200 ====================\n",
            "Train Acc: 0.625845 | Train Loss: 0.975857\n",
            "  Val Acc: 0.676991 |   Val Loss: 0.838340 | LR: 0.002532\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 60/200 ====================\n",
            "Train Acc: 0.655405 | Train Loss: 0.917068\n",
            "  Val Acc: 0.681416 |   Val Loss: 0.835901 | LR: 0.002485\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 63/200 ====================\n",
            "Train Acc: 0.655405 | Train Loss: 0.907376\n",
            "  Val Acc: 0.678466 |   Val Loss: 0.875342 | LR: 0.002436\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Best updated] Saved checkpoint: supurvised.pt (val_loss=0.772383)\n",
            "==================== Epoch 66/200 ====================\n",
            "Train Acc: 0.643581 | Train Loss: 0.891871\n",
            "  Val Acc: 0.707965 |   Val Loss: 0.772383 | LR: 0.002386\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 69/200 ====================\n",
            "Train Acc: 0.638514 | Train Loss: 0.913403\n",
            "  Val Acc: 0.668142 |   Val Loss: 0.887632 | LR: 0.002335\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 72/200 ====================\n",
            "Train Acc: 0.669764 | Train Loss: 0.864099\n",
            "  Val Acc: 0.685841 |   Val Loss: 0.888068 | LR: 0.002282\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Best updated] Saved checkpoint: supurvised.pt (val_loss=0.751706)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 75/200 ====================\n",
            "Train Acc: 0.662162 | Train Loss: 0.894855\n",
            "  Val Acc: 0.699115 |   Val Loss: 0.807790 | LR: 0.002228\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 78/200 ====================\n",
            "Train Acc: 0.679054 | Train Loss: 0.841132\n",
            "  Val Acc: 0.730088 |   Val Loss: 0.761516 | LR: 0.002173\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Best updated] Saved checkpoint: supurvised.pt (val_loss=0.696062)\n",
            "==================== Epoch 81/200 ====================\n",
            "Train Acc: 0.690034 | Train Loss: 0.784447\n",
            "  Val Acc: 0.772861 |   Val Loss: 0.696062 | LR: 0.002118\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 84/200 ====================\n",
            "Train Acc: 0.688345 | Train Loss: 0.830803\n",
            "  Val Acc: 0.727139 |   Val Loss: 0.768872 | LR: 0.002061\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 87/200 ====================\n",
            "Train Acc: 0.720439 | Train Loss: 0.758291\n",
            "  Val Acc: 0.734513 |   Val Loss: 0.774151 | LR: 0.002003\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 90/200 ====================\n",
            "Train Acc: 0.715372 | Train Loss: 0.761606\n",
            "  Val Acc: 0.705015 |   Val Loss: 0.743461 | LR: 0.001946\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 93/200 ====================\n",
            "Train Acc: 0.718750 | Train Loss: 0.742075\n",
            "  Val Acc: 0.740413 |   Val Loss: 0.707693 | LR: 0.001887\n",
            "Early stopping triggered at epoch 93 (val_loss 未改善 12 次)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "################################################################################\n",
        "#     You can adjust those hyper parameters to loop for max_epochs times       #\n",
        "################################################################################\n",
        "max_epochs = 200\n",
        "log_interval = 3\n",
        "# 學習率調度器：CosineAnnealingLR\n",
        "# - T_max：學習率從初始值降到最小值所需的 epoch 數（設為總 epoch 數）\n",
        "# - eta_min：學習率的最小值，默認為 0\n",
        "# - 使用餘弦退火策略，學習率會平滑地從初始值降到最小值\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs, eta_min=0.0005)\n",
        "\n",
        "train_acc_list = []\n",
        "train_loss_list = []\n",
        "val_acc_list = []\n",
        "val_loss_list = []\n",
        "\n",
        "\n",
        "# -------- Early stopping 參數 --------\n",
        "patience = 12  # 如果驗證集連續 N 回合沒有改善就停止\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "best_model_state = None\n",
        "# ------------------------------------\n",
        "\n",
        "\n",
        "for epoch in range(1, max_epochs + 1):\n",
        "    train_acc, train_loss = train(train_loader, model, criterion, optimizer, epoch=epoch, total_epochs=max_epochs)\n",
        "    val_acc, val_loss     = val(val_loader, model, criterion, epoch=epoch, total_epochs=max_epochs)\n",
        "\n",
        "    train_acc_list.append(train_acc)\n",
        "    train_loss_list.append(train_loss)\n",
        "    val_acc_list.append(val_acc)\n",
        "    val_loss_list.append(val_loss)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "      # 紀錄最佳模型權重\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        patience_counter = 0\n",
        "        # 深拷貝一份模型權重\n",
        "        best_model_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
        "        torch.save(model.state_dict(), 'supurvised.pt')\n",
        "        print(f\"[Best updated] Saved checkpoint: {'supurvised.pt'} (val_loss={best_val_loss:.6f})\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "    # 每 log_interval 輸出一次\n",
        "    if epoch % log_interval == 0:\n",
        "        lr = optimizer.param_groups[0]['lr']\n",
        "        print('=' * 20, f'Epoch {epoch}/{max_epochs}', '=' * 20)\n",
        "        print('Train Acc: {:.6f} | Train Loss: {:.6f}'.format(train_acc, train_loss))\n",
        "        print('  Val Acc: {:.6f} |   Val Loss: {:.6f} | LR: {:.6f}'.format(val_acc, val_loss, lr))\n",
        "\n",
        "    # 判斷是否早停\n",
        "    if patience_counter >= patience:\n",
        "        print(f'Early stopping triggered at epoch {epoch} (val_loss 未改善 {patience} 次)')\n",
        "        break\n",
        "\n",
        "\n",
        "################################################################################\n",
        "#                               End of your code                               #\n",
        "################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Y3d4vPxSg-Xw"
      },
      "outputs": [],
      "source": [
        "SUPERVISED_CKPT = 'supurvised.pt'\n",
        "# torch.save(model.state_dict(), SUPERVISED_CKPT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9reJHZ5Rg-Xp"
      },
      "source": [
        "#### Visualize accuracy and loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "id": "lvHqE7Svg-Xv",
        "outputId": "56196729-3f2c-4b98-a12f-3bce7b9467db"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m在目前儲存格或上一個儲存格中執行程式碼時，Kernel 已損毀。\n",
            "\u001b[1;31m請檢閱儲存格中的程式碼，找出失敗的可能原因。\n",
            "\u001b[1;31m如需詳細資訊，請按一下<a href='https://aka.ms/vscodeJupyterKernelCrash'>這裡</a>。\n",
            "\u001b[1;31m如需詳細資料，請檢視 Jupyter <a href='command:jupyter.viewOutput'>記錄</a>。"
          ]
        }
      ],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# plt.figure(figsize=(12, 4))\n",
        "# plt.plot(range(len(train_loss_list)), train_loss_list)\n",
        "# plt.plot(range(len(val_loss_list)), val_loss_list)\n",
        "# plt.legend(['train', 'val'])\n",
        "# plt.title('Loss')\n",
        "# plt.show()\n",
        "\n",
        "# plt.figure(figsize=(12, 4))\n",
        "# plt.plot(range(len(train_acc_list)), train_acc_list)\n",
        "# plt.plot(range(len(val_acc_list)), val_acc_list)\n",
        "# plt.legend(['train', 'val'])\n",
        "# plt.title('Acc')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MvG08C8g-Xw"
      },
      "source": [
        "finish training your classifier, next you should use this classifer to predict unlabel images with pseduo label."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UWP9DSGg-Xw"
      },
      "source": [
        "## Step2: Use unlabeled data to enhance model performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybvV-G7Wg-Xw",
        "outputId": "f6f23a88-40ca-4602-befe-aa87da8d3802"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load the trained classifier weights\n",
        "ckpt = torch.load(SUPERVISED_CKPT, map_location=device)\n",
        "model.load_state_dict(ckpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "muTJHA-cg-Xx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unlabeled pool size: 1202\n"
          ]
        }
      ],
      "source": [
        "# create a unlabeled data set list, we will use it later\n",
        "unlabeled_set_list = []\n",
        "for img in unlabeled_set:\n",
        "    unlabeled_set_list.append(img)\n",
        "\n",
        "print(\"Unlabeled pool size:\", len(unlabeled_set_list))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATMRMmIVg-Xy"
      },
      "source": [
        "### Use the trained classifier to generates pseudo-labels of a dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "GWsix2t7g-Xy"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import ConcatDataset\n",
        "###########################################################\n",
        "#   You can adjust the threshold to get better result !   #\n",
        "###########################################################\n",
        "def get_pseudo_labels(model, threshold=0.85):\n",
        "\n",
        "    global unlabeled_set_list\n",
        "    model.eval()\n",
        "    imgs_keep = []\n",
        "    labels_keep = []\n",
        "    remove_index = []\n",
        "    soft_max = nn.Softmax(dim=1)\n",
        "    with torch.no_grad():\n",
        "        for idx, img in enumerate(tqdm(unlabeled_set_list, desc=\"Pseudo-labeling\", leave=False)):\n",
        "            img = img.to(device)\n",
        "            img = img.unsqueeze(0)  # Add batch dimension\n",
        "            #####################################################################################\n",
        "            #     TODO:                                                                         #\n",
        "            #     1. Foward the data, Using torch.no_grad() accelerates the forward process     #\n",
        "            #     2. obtain the probability distributions by applying softmax on logits         #\n",
        "            #     3. Filter the data with threshold                                             #\n",
        "            #     4. Combine the labeled training data with the pseudo-labeled data             #\n",
        "            #        to construct a new training set. then removed                              #\n",
        "            #     5. the unlabeled data from unlabeled_set_list                                 #\n",
        "            #     hint: ConcatDataset                                                           #\n",
        "            #####################################################################################\n",
        "            # 1. 前向傳播（已在 torch.no_grad() 中，加速推論過程）\n",
        "            outputs = model(img)\n",
        "            # 2. 使用 softmax 獲取機率分布\n",
        "            probs = soft_max(outputs)\n",
        "\n",
        "            # 獲取最大機率和預測類別\n",
        "            max_prob, pred_label = torch.max(probs, 1)\n",
        "\n",
        "            # 3. 根據閾值篩選資料\n",
        "            if max_prob.item() >= threshold:\n",
        "                # 4. 將符合閾值的圖片和標籤加入保留列表\n",
        "                imgs_keep.append(img.squeeze(0).cpu())  # 移除 batch 維度並移到 CPU\n",
        "                labels_keep.append(pred_label.item())\n",
        "                # 5. 記錄要從未標記資料中移除的索引\n",
        "                remove_index.append(idx)\n",
        "            #####################################################################################\n",
        "            #                           End of your code                                        #\n",
        "            #####################################################################################\n",
        "\n",
        "    # Remove processed images from unlabeled list\n",
        "    for i in reversed(remove_index):\n",
        "        del unlabeled_set_list[i]\n",
        "\n",
        "    if imgs_keep:\n",
        "        # Stack on CPU first, then create TensorDataset\n",
        "        pseudo_imgs   = torch.stack(imgs_keep, dim=0)                      # [N, C, H, W] on CPU\n",
        "        pseudo_labels = torch.tensor(labels_keep, dtype=torch.long)        # [N] on CPU\n",
        "        pseudo_dataset = TensorDataset(pseudo_imgs, pseudo_labels)\n",
        "        taken = len(pseudo_dataset)\n",
        "    else:\n",
        "        pseudo_dataset = TensorDataset(torch.empty(0,3,224,224), torch.empty(0,dtype=torch.long))\n",
        "        taken = 0\n",
        "\n",
        "    print(f\"Labeled {taken} images this round. Remaining unlabeled: {len(unlabeled_set_list)}\")\n",
        "\n",
        "    # Clear GPU cache to free memory\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return pseudo_dataset, taken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_IFcw2t-bl4"
      },
      "source": [
        "## Redeifine your optimizer if you want"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "XnjRklvo-bl4"
      },
      "outputs": [],
      "source": [
        "################################################################################\n",
        "# TODO: Define loss and optmizer functions                                     #\n",
        "# Try any loss or optimizer function and learning rate to get better result    #\n",
        "# hint: torch.nn and torch.optim                                               #\n",
        "################################################################################\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.0015, weight_decay=5e-3)\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.2)\n",
        "################################################################################\n",
        "#                               End of your code                               #\n",
        "################################################################################\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRPKdz_sg-Xz"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msM56s7kg-Xz"
      },
      "source": [
        "Let's define train function.  \n",
        "\n",
        "Use the **get_pseudo_labels** function to get the new training set, then construct a new data loader for training.\n",
        "\n",
        "It will iterate input data 1 epoch and update model with optmizer.  \n",
        "\n",
        "Finally, calculate mean loss and total accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "EAeLnU3Ng-Xz",
        "outputId": "ddaed4c7-7580-4732-967b-be00290806ab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                     \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 392 images this round. Remaining unlabeled: 810\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 1 images this round. Remaining unlabeled: 809\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 11 images this round. Remaining unlabeled: 798\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 3/100 ====================\n",
            "Train Acc: 0.791250 | Train Loss: 1.018218\n",
            "  Val Acc: 0.737463 |   Val Loss: 1.084716 | LR: 0.001497\n",
            "Dataset Size: 1604 (original: 1200, pseudo: 404)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 2 images this round. Remaining unlabeled: 796\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 5 images this round. Remaining unlabeled: 791\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 1 images this round. Remaining unlabeled: 790\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 6/100 ====================\n",
            "Train Acc: 0.802500 | Train Loss: 0.985827\n",
            "  Val Acc: 0.733038 |   Val Loss: 1.061900 | LR: 0.001489\n",
            "Dataset Size: 1612 (original: 1200, pseudo: 412)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 6 images this round. Remaining unlabeled: 784\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 2 images this round. Remaining unlabeled: 782\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 0 images this round. Remaining unlabeled: 782\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 9/100 ====================\n",
            "Train Acc: 0.787500 | Train Loss: 0.993441\n",
            "  Val Acc: 0.746313 |   Val Loss: 1.054505 | LR: 0.001476\n",
            "Dataset Size: 1620 (original: 1200, pseudo: 420)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 0 images this round. Remaining unlabeled: 782\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 4 images this round. Remaining unlabeled: 778\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 4 images this round. Remaining unlabeled: 774\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 12/100 ====================\n",
            "Train Acc: 0.811875 | Train Loss: 0.969944\n",
            "  Val Acc: 0.761062 |   Val Loss: 1.044035 | LR: 0.001458\n",
            "Dataset Size: 1628 (original: 1200, pseudo: 428)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 15 images this round. Remaining unlabeled: 759\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 1 images this round. Remaining unlabeled: 758\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 4 images this round. Remaining unlabeled: 754\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 15/100 ====================\n",
            "Train Acc: 0.826593 | Train Loss: 0.958251\n",
            "  Val Acc: 0.777286 |   Val Loss: 1.018494 | LR: 0.001435\n",
            "Dataset Size: 1648 (original: 1200, pseudo: 448)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 1 images this round. Remaining unlabeled: 753\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 6 images this round. Remaining unlabeled: 747\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 1 images this round. Remaining unlabeled: 746\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 18/100 ====================\n",
            "Train Acc: 0.817402 | Train Loss: 0.950032\n",
            "  Val Acc: 0.771386 |   Val Loss: 1.026012 | LR: 0.001407\n",
            "Dataset Size: 1656 (original: 1200, pseudo: 456)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 2 images this round. Remaining unlabeled: 744\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 3 images this round. Remaining unlabeled: 741\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 26 images this round. Remaining unlabeled: 715\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 21/100 ====================\n",
            "Train Acc: 0.831731 | Train Loss: 0.934834\n",
            "  Val Acc: 0.761062 |   Val Loss: 1.034983 | LR: 0.001374\n",
            "Dataset Size: 1687 (original: 1200, pseudo: 487)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 4 images this round. Remaining unlabeled: 711\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 1 images this round. Remaining unlabeled: 710\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 0 images this round. Remaining unlabeled: 710\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 24/100 ====================\n",
            "Train Acc: 0.852163 | Train Loss: 0.913880\n",
            "  Val Acc: 0.764012 |   Val Loss: 1.031165 | LR: 0.001337\n",
            "Dataset Size: 1692 (original: 1200, pseudo: 492)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 1 images this round. Remaining unlabeled: 709\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 6 images this round. Remaining unlabeled: 703\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 0 images this round. Remaining unlabeled: 703\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 27/100 ====================\n",
            "Train Acc: 0.849646 | Train Loss: 0.908944\n",
            "  Val Acc: 0.774336 |   Val Loss: 1.024380 | LR: 0.001297\n",
            "Dataset Size: 1699 (original: 1200, pseudo: 499)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 11 images this round. Remaining unlabeled: 692\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 1 images this round. Remaining unlabeled: 691\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 2 images this round. Remaining unlabeled: 689\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 30/100 ====================\n",
            "Train Acc: 0.840802 | Train Loss: 0.913357\n",
            "  Val Acc: 0.778761 |   Val Loss: 1.007265 | LR: 0.001253\n",
            "Dataset Size: 1713 (original: 1200, pseudo: 513)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 5 images this round. Remaining unlabeled: 684\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 2 images this round. Remaining unlabeled: 682\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 1 images this round. Remaining unlabeled: 681\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 33/100 ====================\n",
            "Train Acc: 0.851415 | Train Loss: 0.910108\n",
            "  Val Acc: 0.771386 |   Val Loss: 1.009460 | LR: 0.001205\n",
            "Dataset Size: 1721 (original: 1200, pseudo: 521)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 1 images this round. Remaining unlabeled: 680\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 0 images this round. Remaining unlabeled: 680\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 2 images this round. Remaining unlabeled: 678\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 36/100 ====================\n",
            "Train Acc: 0.863797 | Train Loss: 0.892911\n",
            "  Val Acc: 0.777286 |   Val Loss: 1.014935 | LR: 0.001155\n",
            "Dataset Size: 1724 (original: 1200, pseudo: 524)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 2 images this round. Remaining unlabeled: 676\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 0 images this round. Remaining unlabeled: 676\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 2 images this round. Remaining unlabeled: 674\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 39/100 ====================\n",
            "Train Acc: 0.862847 | Train Loss: 0.882149\n",
            "  Val Acc: 0.802360 |   Val Loss: 0.979333 | LR: 0.001103\n",
            "Dataset Size: 1728 (original: 1200, pseudo: 528)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 1 images this round. Remaining unlabeled: 673\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 2 images this round. Remaining unlabeled: 671\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 2 images this round. Remaining unlabeled: 669\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 42/100 ====================\n",
            "Train Acc: 0.854167 | Train Loss: 0.887021\n",
            "  Val Acc: 0.778761 |   Val Loss: 0.995715 | LR: 0.001049\n",
            "Dataset Size: 1733 (original: 1200, pseudo: 533)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 0 images this round. Remaining unlabeled: 669\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 1 images this round. Remaining unlabeled: 668\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 2 images this round. Remaining unlabeled: 666\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 45/100 ====================\n",
            "Train Acc: 0.871528 | Train Loss: 0.863057\n",
            "  Val Acc: 0.811209 |   Val Loss: 0.963188 | LR: 0.000994\n",
            "Dataset Size: 1736 (original: 1200, pseudo: 536)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 1 images this round. Remaining unlabeled: 665\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 0 images this round. Remaining unlabeled: 665\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 2 images this round. Remaining unlabeled: 663\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 48/100 ====================\n",
            "Train Acc: 0.873843 | Train Loss: 0.866879\n",
            "  Val Acc: 0.808260 |   Val Loss: 0.968547 | LR: 0.000938\n",
            "Dataset Size: 1739 (original: 1200, pseudo: 539)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 2 images this round. Remaining unlabeled: 661\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 3 images this round. Remaining unlabeled: 658\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 6 images this round. Remaining unlabeled: 652\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 51/100 ====================\n",
            "Train Acc: 0.885417 | Train Loss: 0.853097\n",
            "  Val Acc: 0.787611 |   Val Loss: 0.994183 | LR: 0.000881\n",
            "Dataset Size: 1750 (original: 1200, pseudo: 550)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 0 images this round. Remaining unlabeled: 652\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 2 images this round. Remaining unlabeled: 650\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 0 images this round. Remaining unlabeled: 650\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 54/100 ====================\n",
            "Train Acc: 0.883681 | Train Loss: 0.853648\n",
            "  Val Acc: 0.800885 |   Val Loss: 0.976988 | LR: 0.000825\n",
            "Dataset Size: 1752 (original: 1200, pseudo: 552)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 0 images this round. Remaining unlabeled: 650\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 1 images this round. Remaining unlabeled: 649\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 0 images this round. Remaining unlabeled: 649\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 57/100 ====================\n",
            "Train Acc: 0.883681 | Train Loss: 0.842655\n",
            "  Val Acc: 0.825959 |   Val Loss: 0.956168 | LR: 0.000769\n",
            "Dataset Size: 1753 (original: 1200, pseudo: 553)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 2 images this round. Remaining unlabeled: 647\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 2 images this round. Remaining unlabeled: 645\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 0 images this round. Remaining unlabeled: 645\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 60/100 ====================\n",
            "Train Acc: 0.888889 | Train Loss: 0.838618\n",
            "  Val Acc: 0.815634 |   Val Loss: 0.956799 | LR: 0.000715\n",
            "Dataset Size: 1757 (original: 1200, pseudo: 557)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 1 images this round. Remaining unlabeled: 644\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 1 images this round. Remaining unlabeled: 643\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 0 images this round. Remaining unlabeled: 643\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 63/100 ====================\n",
            "Train Acc: 0.903935 | Train Loss: 0.823237\n",
            "  Val Acc: 0.793510 |   Val Loss: 0.967356 | LR: 0.000662\n",
            "Dataset Size: 1759 (original: 1200, pseudo: 559)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 0 images this round. Remaining unlabeled: 643\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 2 images this round. Remaining unlabeled: 641\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 0 images this round. Remaining unlabeled: 641\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 66/100 ====================\n",
            "Train Acc: 0.913068 | Train Loss: 0.807223\n",
            "  Val Acc: 0.812684 |   Val Loss: 0.951291 | LR: 0.000611\n",
            "Dataset Size: 1761 (original: 1200, pseudo: 561)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 1 images this round. Remaining unlabeled: 640\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 0 images this round. Remaining unlabeled: 640\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 0 images this round. Remaining unlabeled: 640\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 69/100 ====================\n",
            "Train Acc: 0.903409 | Train Loss: 0.820982\n",
            "  Val Acc: 0.818584 |   Val Loss: 0.950482 | LR: 0.000563\n",
            "Dataset Size: 1762 (original: 1200, pseudo: 562)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 1 images this round. Remaining unlabeled: 639\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 2 images this round. Remaining unlabeled: 637\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 1 images this round. Remaining unlabeled: 636\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 72/100 ====================\n",
            "Train Acc: 0.896591 | Train Loss: 0.822888\n",
            "  Val Acc: 0.825959 |   Val Loss: 0.938560 | LR: 0.000518\n",
            "Dataset Size: 1766 (original: 1200, pseudo: 566)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 2 images this round. Remaining unlabeled: 634\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 2 images this round. Remaining unlabeled: 632\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 1 images this round. Remaining unlabeled: 631\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 75/100 ====================\n",
            "Train Acc: 0.903409 | Train Loss: 0.816852\n",
            "  Val Acc: 0.805310 |   Val Loss: 0.959440 | LR: 0.000476\n",
            "Dataset Size: 1771 (original: 1200, pseudo: 571)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 0 images this round. Remaining unlabeled: 631\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 0 images this round. Remaining unlabeled: 631\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 0 images this round. Remaining unlabeled: 631\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== Epoch 78/100 ====================\n",
            "Train Acc: 0.912500 | Train Loss: 0.809438\n",
            "  Val Acc: 0.833333 |   Val Loss: 0.943539 | LR: 0.000438\n",
            "Dataset Size: 1771 (original: 1200, pseudo: 571)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeled 0 images this round. Remaining unlabeled: 631\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[SSL] Early stopping at epoch 79: val_loss 未改善 12 次，最佳 val_loss=0.935457\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.setrecursionlimit(1000000)\n",
        "\n",
        "#########################################################################################################\n",
        "#         You can adjust those hyper parameters like epochs or threshold for training                   #\n",
        "#########################################################################################################\n",
        "n_epochs = 100\n",
        "N = 1  # Update synthesis dataset every N epochs\n",
        "log_interval =3  # Log every N epochs like supervised training\n",
        "best_acc = 0.0\n",
        "SELF_TRAIN_CKPT = 'self_training.pt'\n",
        "\n",
        "\n",
        "patience_ssl = 12                    # 連續多少個 epoch 沒改善就停\n",
        "best_val_loss_ssl = float('inf')    # 目前最佳驗證損失\n",
        "patience_counter_ssl = 0            # 沒改善的累計次數\n",
        "\n",
        "# 學習率調度器：CosineAnnealingLR (用於自我訓練階段)\n",
        "# - T_max：設為自我訓練的總 epoch 數\n",
        "# - eta_min：最小學習率設為初始學習率的 1/10\n",
        "scheduler_ssl = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=n_epochs, eta_min=0.0003)\n",
        "\n",
        "\n",
        "# Initialize with original labeled data\n",
        "current_train_dataset = train_set\n",
        "train_loader_ssl = train_loader  # Initialize with original train loader\n",
        "all_pseudo_datasets = []  # Store all pseudo datasets to accumulate them\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    #########################################################################################################\n",
        "    #    TODO:                                                                                              #\n",
        "    #    In each epoch, relabel the unlabeled dataset for semi-supervised learning.                         #\n",
        "    #    1. Obtain pseudo-labels for unlabeled data using trained model.(use get_pseudo_labels function)    #\n",
        "    #    2. Construct a new dataset and a data loader for training.                                         #\n",
        "    #    You can try different way to use the get_pseudo_label function maybe will get the better result.   #                                  #\n",
        "    #########################################################################################################\n",
        "     # 每 N 個 epoch 更新一次偽標籤\n",
        "    if (epoch + 1) % N == 0:\n",
        "        pseudo_dataset, taken = get_pseudo_labels(model, threshold=0.9)\n",
        "\n",
        "        if taken > 0:\n",
        "          all_pseudo_datasets.append(pseudo_dataset)\n",
        "\n",
        "      # 合併數據集\n",
        "        if all_pseudo_datasets:\n",
        "            current_train_dataset = ConcatDataset([train_set] + all_pseudo_datasets)\n",
        "        else:\n",
        "            current_train_dataset = train_set\n",
        "\n",
        "        # 重建數據加載器\n",
        "        train_loader_ssl = DataLoader(\n",
        "            current_train_dataset,\n",
        "            shuffle=True,\n",
        "            drop_last=True,\n",
        "            **loader_kwargs\n",
        "        )\n",
        "    #########################################################################################################\n",
        "    #                                          End of your code                                             #\n",
        "    #########################################################################################################\n",
        "\n",
        "    try:\n",
        "        # ---------- Training using the train function from above ----------\n",
        "        train_acc, train_loss = train(train_loader_ssl, model, criterion, optimizer, epoch=epoch+1, total_epochs=n_epochs)\n",
        "\n",
        "        # ---------- Validation ----------\n",
        "        valid_acc, valid_loss = val(val_loader, model, criterion, epoch=epoch+1, total_epochs=n_epochs)\n",
        "\n",
        "                # >>> [Early Stopping - SSL]：以驗證損失作為是否「改善」的判準 <<<\n",
        "        if valid_loss < best_val_loss_ssl:\n",
        "            best_val_loss_ssl = valid_loss\n",
        "            patience_counter_ssl = 0\n",
        "            # 也一併更新對應的 acc 記錄（僅供觀察，不作為 early stopping 判斷）\n",
        "            best_acc = max(best_acc, valid_acc)\n",
        "            torch.save(model.state_dict(), SELF_TRAIN_CKPT)  # 保存目前最佳權重\n",
        "        else:\n",
        "            patience_counter_ssl += 1\n",
        "        # <<< [Early Stopping - SSL] 結束 >>>\n",
        "\n",
        "        # 學習率調整\n",
        "        scheduler_ssl.step()\n",
        "\n",
        "        # 記錄/輸出\n",
        "        if (epoch + 1) % log_interval == 0:\n",
        "            lr = optimizer.param_groups[0]['lr']\n",
        "            total_pseudo = sum(len(dataset) for dataset in all_pseudo_datasets)\n",
        "            print('=' * 20, f'Epoch {epoch+1}/{n_epochs}', '=' * 20)\n",
        "            print('Train Acc: {:.6f} | Train Loss: {:.6f}'.format(train_acc, train_loss))\n",
        "            print('  Val Acc: {:.6f} |   Val Loss: {:.6f} | LR: {:.6f}'.format(valid_acc, valid_loss, lr))\n",
        "            print('Dataset Size: {} (original: {}, pseudo: {})'.format(len(current_train_dataset), len(train_set), total_pseudo))\n",
        "\n",
        "        # >>> [Early Stopping - SSL]：達到耐心上限則提前停止 <<<\n",
        "        if patience_counter_ssl >= patience_ssl:\n",
        "            print(f'[SSL] Early stopping at epoch {epoch+1}: val_loss 未改善 {patience_ssl} 次，最佳 val_loss={best_val_loss_ssl:.6f}')\n",
        "            break\n",
        "        # <<< [Early Stopping - SSL] 結束 >>>\n",
        "\n",
        "    except RuntimeError as e:\n",
        "        print(f\"CUDA error during training epoch {epoch+1}: {e}\")\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        # Optionally reduce batch size if memory error\n",
        "        if \"out of memory\" in str(e).lower():\n",
        "            new_batch_size = max(batch_size // 2, 1)\n",
        "            loader_kwargs_reduced = loader_kwargs.copy()\n",
        "            loader_kwargs_reduced['batch_size'] = new_batch_size\n",
        "            loader_kwargs_reduced['drop_last'] = True   # <— 補這行\n",
        "\n",
        "            train_loader_ssl = DataLoader(\n",
        "                current_train_dataset,\n",
        "                shuffle=True,\n",
        "                **loader_kwargs_reduced\n",
        "            )\n",
        "\n",
        "#########################################################################################################\n",
        "#                               End of your code                                                        #\n",
        "#########################################################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8awaE981g-X0"
      },
      "source": [
        "### Predict Result\n",
        "\n",
        "Predict the labesl based on testing set. Upload to [Kaggle](https://www.kaggle.com/t/a611e0096e5943cc99a1c0545be28c3c).\n",
        "\n",
        "**How to upload**\n",
        "\n",
        "1. Click the folder icon in the left hand side of Colab.\n",
        "2. Right click \"result.csv\". Select \"Download\"\n",
        "3. To kaggle. Click \"Submit Predictions\"\n",
        "4. Upload the result.csv\n",
        "5. System will automaticlaly calculate the accuracy of 50% dataset and publish this result to leaderboard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "DCeiMZwRg-X0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# if you wanna load previous best model\n",
        "ckpt = torch.load('self_training.pt', map_location=device)\n",
        "model.load_state_dict(ckpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "UzuQekVhg-X0"
      },
      "outputs": [],
      "source": [
        "test_set = FlowerData(data_folder, split='test', mode='test', transform=transforms_test)\n",
        "test_loader = DataLoader(\n",
        "    test_set,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    shuffle=False,\n",
        "    pin_memory=torch.cuda.is_available()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "OhXdQLJ_g-X1"
      },
      "outputs": [],
      "source": [
        "def predict(input_data, model):\n",
        "    model.eval()\n",
        "    output_list = []\n",
        "    with torch.no_grad():\n",
        "        for images in input_data:\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            output_list.extend(predicted.to('cpu').numpy().tolist())\n",
        "    return output_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "NHAgTI4Jg-X1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved predictions to result.csv\n"
          ]
        }
      ],
      "source": [
        "pred_indices = predict(test_loader, model)\n",
        "\n",
        "with open('result.csv', 'w', newline='') as csvFile:\n",
        "    writer = csv.DictWriter(csvFile, fieldnames=['ID', 'label'])\n",
        "    writer.writeheader()\n",
        "    for filename, pred in zip(test_set.paths, pred_indices):\n",
        "        filename = osp.basename(filename)  # Extract just the filename\n",
        "        writer.writerow({'ID': filename, 'label': CLASS_NAMES[int(pred)]})\n",
        "\n",
        "print(\"Saved predictions to result.csv\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
